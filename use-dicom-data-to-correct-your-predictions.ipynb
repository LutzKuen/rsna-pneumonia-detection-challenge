{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "This kernel is a fork from Jonne's kernel (https://www.kaggle.com/jonnedtc/cnn-segmentation-connected-components). Jonne creates a submission using a convolutional neural network. However, Jonne does not use any DICOM data for the prediction. I am creating this kernel to improve on Jonne's predictions by using the DICOM data. The model I am using is LightGBM, since it is fast, often accurate, and reliable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "source": [
    "This kernel is also a fork from jtlowery's kernel (https://www.kaggle.com/jtlowery/intro-eda-with-dicom-metadata). Jtlowery's kernel has functions I can copy to read in the DICOM data.[](http://)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "21e7abc8829ed96d63ba46f3b1813019371a9185"
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from collections import defaultdict\n",
    "import pydicom\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "%matplotlib inline\n",
    "\n",
    "np.warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "d4ba2208dce9ad05faac5eb87135a342dc7ed3b5"
   },
   "outputs": [],
   "source": [
    "DATA_DIR = '../pneumonia_data'\n",
    "IMAGE_DIR = '../pneumonia_data/test_images'\n",
    "labels = pd.read_csv(DATA_DIR+'/stage_1_train_labels.csv')\n",
    "details = pd.read_csv(DATA_DIR+'/stage_1_detailed_class_info.csv')\n",
    "# duplicates in details just have the same class so can be safely dropped\n",
    "details = details.drop_duplicates('patientId').reset_index(drop=True)\n",
    "labels_w_class = labels.merge(details, how='inner', on='patientId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "fb7fa287367ede92a82ac85e4a7ec80fe9989290"
   },
   "outputs": [],
   "source": [
    "# get lists of all train/test dicom filepaths\n",
    "train_dcm_fps = glob.glob(IMAGE_DIR+'/*.dcm')\n",
    "test_dcm_fps = glob.glob(IMAGE_DIR+'/*.dcm')\n",
    "\n",
    "train_dcms = [pydicom.read_file(x, stop_before_pixels=True) for x in train_dcm_fps]\n",
    "test_dcms = [pydicom.read_file(x, stop_before_pixels=True) for x in test_dcm_fps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "0d80a30b21c870f73e06e9c3516e742210d636eb"
   },
   "outputs": [],
   "source": [
    "def parse_dcm_metadata(dcm):\n",
    "    unpacked_data = {}\n",
    "    group_elem_to_keywords = {}\n",
    "    # iterating here to force conversion from lazy RawDataElement to DataElement\n",
    "    for d in dcm:\n",
    "        pass\n",
    "    # keys are pydicom.tag.BaseTag, values are pydicom.dataelem.DataElement\n",
    "    for tag, elem in dcm.items():\n",
    "        tag_group = tag.group\n",
    "        tag_elem = tag.elem\n",
    "        keyword = elem.keyword\n",
    "        group_elem_to_keywords[(tag_group, tag_elem)] = keyword\n",
    "        value = elem.value\n",
    "        unpacked_data[keyword] = value\n",
    "    return unpacked_data, group_elem_to_keywords\n",
    "\n",
    "train_meta_dicts, tag_to_keyword_train = zip(*[parse_dcm_metadata(x) for x in train_dcms])\n",
    "test_meta_dicts, tag_to_keyword_test = zip(*[parse_dcm_metadata(x) for x in test_dcms])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "a27e35027993fcb50790b46e01ff5b719805ca41"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(8, 5): 'SpecificCharacterSet',\n",
       " (8, 22): 'SOPClassUID',\n",
       " (8, 24): 'SOPInstanceUID',\n",
       " (8, 32): 'StudyDate',\n",
       " (8, 48): 'StudyTime',\n",
       " (8, 80): 'AccessionNumber',\n",
       " (8, 96): 'Modality',\n",
       " (8, 100): 'ConversionType',\n",
       " (8, 144): 'ReferringPhysicianName',\n",
       " (8, 4158): 'SeriesDescription',\n",
       " (16, 16): 'PatientName',\n",
       " (16, 32): 'PatientID',\n",
       " (16, 48): 'PatientBirthDate',\n",
       " (16, 64): 'PatientSex',\n",
       " (16, 4112): 'PatientAge',\n",
       " (24, 21): 'BodyPartExamined',\n",
       " (24, 20737): 'ViewPosition',\n",
       " (32, 13): 'StudyInstanceUID',\n",
       " (32, 14): 'SeriesInstanceUID',\n",
       " (32, 16): 'StudyID',\n",
       " (32, 17): 'SeriesNumber',\n",
       " (32, 19): 'InstanceNumber',\n",
       " (32, 32): 'PatientOrientation',\n",
       " (40, 2): 'SamplesPerPixel',\n",
       " (40, 4): 'PhotometricInterpretation',\n",
       " (40, 16): 'Rows',\n",
       " (40, 17): 'Columns',\n",
       " (40, 48): 'PixelSpacing',\n",
       " (40, 256): 'BitsAllocated',\n",
       " (40, 257): 'BitsStored',\n",
       " (40, 258): 'HighBit',\n",
       " (40, 259): 'PixelRepresentation',\n",
       " (40, 8464): 'LossyImageCompression',\n",
       " (40, 8468): 'LossyImageCompressionMethod'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# join all the dicts\n",
    "unified_tag_to_key_train = {k:v for dict_ in tag_to_keyword_train for k,v in dict_.items()}\n",
    "unified_tag_to_key_test = {k:v for dict_ in tag_to_keyword_test for k,v in dict_.items()}\n",
    "\n",
    "# quick check to make sure there are no different keys between test/train\n",
    "assert len(set(unified_tag_to_key_test.keys()).symmetric_difference(set(unified_tag_to_key_train.keys()))) == 0\n",
    "\n",
    "tag_to_key = {**unified_tag_to_key_test, **unified_tag_to_key_train}\n",
    "tag_to_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "6bd49ed8df9396908ed0d8c9e9af86069b62c56e"
   },
   "outputs": [],
   "source": [
    "# using from_records here since some values in the dicts will be iterables and some are constants\n",
    "train_df = pd.DataFrame.from_records(data=train_meta_dicts)\n",
    "test_df = pd.DataFrame.from_records(data=test_meta_dicts)\n",
    "train_df['dataset'] = 'train'\n",
    "test_df['dataset'] = 'test'\n",
    "df = pd.concat([train_df, test_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "a0a571df8d8be4779dc7013fa6bef6757d2ca8ed"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AccessionNumber</th>\n",
       "      <th>BitsAllocated</th>\n",
       "      <th>BitsStored</th>\n",
       "      <th>BodyPartExamined</th>\n",
       "      <th>Columns</th>\n",
       "      <th>ConversionType</th>\n",
       "      <th>HighBit</th>\n",
       "      <th>InstanceNumber</th>\n",
       "      <th>LossyImageCompression</th>\n",
       "      <th>LossyImageCompressionMethod</th>\n",
       "      <th>...</th>\n",
       "      <th>SeriesDescription</th>\n",
       "      <th>SeriesInstanceUID</th>\n",
       "      <th>SeriesNumber</th>\n",
       "      <th>SpecificCharacterSet</th>\n",
       "      <th>StudyDate</th>\n",
       "      <th>StudyID</th>\n",
       "      <th>StudyInstanceUID</th>\n",
       "      <th>StudyTime</th>\n",
       "      <th>ViewPosition</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>CHEST</td>\n",
       "      <td>1024</td>\n",
       "      <td>WSD</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>01</td>\n",
       "      <td>ISO_10918_1</td>\n",
       "      <td>...</td>\n",
       "      <td>view: AP</td>\n",
       "      <td>1.2.276.0.7230010.3.1.3.8323329.20023.15178744...</td>\n",
       "      <td>1</td>\n",
       "      <td>ISO_IR 100</td>\n",
       "      <td>19010101</td>\n",
       "      <td></td>\n",
       "      <td>1.2.276.0.7230010.3.1.2.8323329.20023.15178744...</td>\n",
       "      <td>000000.00</td>\n",
       "      <td>AP</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  AccessionNumber  BitsAllocated  BitsStored BodyPartExamined  Columns  \\\n",
       "0                              8           8            CHEST     1024   \n",
       "\n",
       "  ConversionType  HighBit  InstanceNumber LossyImageCompression  \\\n",
       "0            WSD        7               1                    01   \n",
       "\n",
       "  LossyImageCompressionMethod   ...   SeriesDescription  \\\n",
       "0                 ISO_10918_1   ...            view: AP   \n",
       "\n",
       "                                   SeriesInstanceUID SeriesNumber  \\\n",
       "0  1.2.276.0.7230010.3.1.3.8323329.20023.15178744...            1   \n",
       "\n",
       "  SpecificCharacterSet StudyDate StudyID  \\\n",
       "0           ISO_IR 100  19010101           \n",
       "\n",
       "                                    StudyInstanceUID  StudyTime  ViewPosition  \\\n",
       "0  1.2.276.0.7230010.3.1.2.8323329.20023.15178744...  000000.00            AP   \n",
       "\n",
       "  dataset  \n",
       "0   train  \n",
       "\n",
       "[1 rows x 35 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "2cac5e5330864378443105bac125ec00525f9095"
   },
   "outputs": [],
   "source": [
    "# separating PixelSpacing list to single values\n",
    "df['PixelSpacing_x'] = df['PixelSpacing'].apply(lambda x: x[0])\n",
    "df['PixelSpacing_y'] = df['PixelSpacing'].apply(lambda x: x[1])\n",
    "df = df.drop(['PixelSpacing'], axis='columns')\n",
    "\n",
    "# x and y are always the same\n",
    "assert sum(df['PixelSpacing_x'] != df['PixelSpacing_y']) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "122f7f17f51e9792c21e4c9b41e69d56a8f983b9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'view: AP', 'view: PA'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ReferringPhysicianName appears to just be empty strings\n",
    "assert sum(df['ReferringPhysicianName'] != '') == 0\n",
    "\n",
    "# SeriesDescription appears to be 'view: {}'.format(ViewPosition)\n",
    "set(df['SeriesDescription'].unique())\n",
    "\n",
    "# so these two columns don't have any useful info and can be safely dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "b0b5ddcf2a95f4dca61071feea897290f55acd27"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AccessionNumber                   1\n",
       "BitsAllocated                     1\n",
       "BitsStored                        1\n",
       "BodyPartExamined                  1\n",
       "Columns                           1\n",
       "ConversionType                    1\n",
       "HighBit                           1\n",
       "InstanceNumber                    1\n",
       "LossyImageCompression             1\n",
       "LossyImageCompressionMethod       1\n",
       "Modality                          1\n",
       "PatientAge                       79\n",
       "PatientBirthDate                  1\n",
       "PatientID                      1000\n",
       "PatientName                    2000\n",
       "PatientOrientation                1\n",
       "PatientSex                        2\n",
       "PhotometricInterpretation         1\n",
       "PixelRepresentation               1\n",
       "ReferringPhysicianName          875\n",
       "Rows                              1\n",
       "SOPClassUID                       1\n",
       "SOPInstanceUID                 1000\n",
       "SamplesPerPixel                   1\n",
       "SeriesDescription                 2\n",
       "SeriesInstanceUID              1000\n",
       "SeriesNumber                      1\n",
       "SpecificCharacterSet              1\n",
       "StudyDate                         1\n",
       "StudyID                           1\n",
       "StudyInstanceUID               1000\n",
       "StudyTime                         1\n",
       "ViewPosition                      2\n",
       "dataset                           2\n",
       "PixelSpacing_x                    7\n",
       "PixelSpacing_y                    7\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nunique_all = df.aggregate('nunique')\n",
    "nunique_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "851e6dbbe0f1307b7d488a85bb0afbe8d2a0ad6f"
   },
   "outputs": [],
   "source": [
    "# drop constant cols and other two from above\n",
    "#ReferringPhysicianName is all ''\n",
    "#PatientName is the same as PatientID\n",
    "#PixelSpacing_y is the same as PixelSpacing_x\n",
    "#The series and SOP UID's are just random numbers / id's, so I'm deleting them too\n",
    "df = df.drop(nunique_all[nunique_all == 1].index.tolist() + ['SeriesDescription', 'ReferringPhysicianName', 'PatientName', 'PixelSpacing_y', 'SOPInstanceUID','SeriesInstanceUID','StudyInstanceUID'], axis='columns')\n",
    "\n",
    "# now that we have a clean metadata dataframe we can merge back to our initial tabular data with target and class info\n",
    "df = df.merge(labels_w_class, how='left', left_on='PatientID', right_on='patientId')\n",
    "\n",
    "df['PatientAge'] = df['PatientAge'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "6add74499872d566d7a43350bb44313afaf31e10"
   },
   "outputs": [],
   "source": [
    "# df now has multiple rows for some patients (those with multiple bounding boxes in label_w_class)\n",
    "# so creating one with no duplicates for patients\n",
    "df_deduped = df.drop_duplicates('PatientID', keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "863c112caa0c8c3dcc3ed7490da4a1c2eae16bc6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PatientAge</th>\n",
       "      <th>PatientID</th>\n",
       "      <th>PatientSex</th>\n",
       "      <th>ViewPosition</th>\n",
       "      <th>dataset</th>\n",
       "      <th>PixelSpacing_x</th>\n",
       "      <th>patientId</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>Target</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>000924cf-0f8d-42bd-9158-1af53881a557</td>\n",
       "      <td>F</td>\n",
       "      <td>AP</td>\n",
       "      <td>train</td>\n",
       "      <td>0.139000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>000db696-cf54-4385-b10b-6b16fbb3f985</td>\n",
       "      <td>F</td>\n",
       "      <td>AP</td>\n",
       "      <td>train</td>\n",
       "      <td>0.168000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40</td>\n",
       "      <td>000fe35a-2649-43d4-b027-e67796d412e0</td>\n",
       "      <td>M</td>\n",
       "      <td>AP</td>\n",
       "      <td>train</td>\n",
       "      <td>0.171000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>57</td>\n",
       "      <td>001031d9-f904-4a23-b3e5-2c088acd19c6</td>\n",
       "      <td>M</td>\n",
       "      <td>PA</td>\n",
       "      <td>train</td>\n",
       "      <td>0.139000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>0010f549-b242-4e94-87a8-57d79de215fc</td>\n",
       "      <td>M</td>\n",
       "      <td>PA</td>\n",
       "      <td>train</td>\n",
       "      <td>0.194311</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PatientAge                             PatientID PatientSex ViewPosition  \\\n",
       "0          19  000924cf-0f8d-42bd-9158-1af53881a557          F           AP   \n",
       "1          25  000db696-cf54-4385-b10b-6b16fbb3f985          F           AP   \n",
       "2          40  000fe35a-2649-43d4-b027-e67796d412e0          M           AP   \n",
       "3          57  001031d9-f904-4a23-b3e5-2c088acd19c6          M           PA   \n",
       "4          56  0010f549-b242-4e94-87a8-57d79de215fc          M           PA   \n",
       "\n",
       "  dataset  PixelSpacing_x patientId   x   y  width  height  Target class  \n",
       "0   train        0.139000       NaN NaN NaN    NaN     NaN     NaN   NaN  \n",
       "1   train        0.168000       NaN NaN NaN    NaN     NaN     NaN   NaN  \n",
       "2   train        0.171000       NaN NaN NaN    NaN     NaN     NaN   NaN  \n",
       "3   train        0.139000       NaN NaN NaN    NaN     NaN     NaN   NaN  \n",
       "4   train        0.194311       NaN NaN NaN    NaN     NaN     NaN   NaN  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_deduped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "8a5329528c7f3566bd194dc774585f4f37c0641f"
   },
   "outputs": [],
   "source": [
    "#Correct ages that are mistyped\n",
    "df_deduped.loc[df_deduped['PatientAge'] > 140, 'PatientAge'] = df_deduped.loc[df_deduped['PatientAge'] > 140, 'PatientAge'] - 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "cf93824822563b455df8bd7a1c07d738765083dd"
   },
   "outputs": [],
   "source": [
    "#Convert binary features from categorical to 0/1\n",
    "# Categorical features with Binary encode (0 or 1; two categories)\n",
    "for bin_feature in ['PatientSex', 'ViewPosition']:\n",
    "    df_deduped[bin_feature], uniques = pd.factorize(df_deduped[bin_feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "1542b266153f540cb41fd3b41dfef56493837582"
   },
   "outputs": [],
   "source": [
    "#Drop the duplicated column patientID\n",
    "del df_deduped['patientId']\n",
    "\n",
    "#Drop columns that are going to be repetitive\n",
    "del df_deduped['dataset']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "61731bdcbb364a16517c4ea526288f5db6f4948e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PatientAge</th>\n",
       "      <th>PatientID</th>\n",
       "      <th>PatientSex</th>\n",
       "      <th>ViewPosition</th>\n",
       "      <th>PixelSpacing_x</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>Target</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>000924cf-0f8d-42bd-9158-1af53881a557</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.139000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>000db696-cf54-4385-b10b-6b16fbb3f985</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.168000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40</td>\n",
       "      <td>000fe35a-2649-43d4-b027-e67796d412e0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.171000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>57</td>\n",
       "      <td>001031d9-f904-4a23-b3e5-2c088acd19c6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.139000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>0010f549-b242-4e94-87a8-57d79de215fc</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.194311</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PatientAge                             PatientID  PatientSex  ViewPosition  \\\n",
       "0          19  000924cf-0f8d-42bd-9158-1af53881a557           0             0   \n",
       "1          25  000db696-cf54-4385-b10b-6b16fbb3f985           0             0   \n",
       "2          40  000fe35a-2649-43d4-b027-e67796d412e0           1             0   \n",
       "3          57  001031d9-f904-4a23-b3e5-2c088acd19c6           1             1   \n",
       "4          56  0010f549-b242-4e94-87a8-57d79de215fc           1             1   \n",
       "\n",
       "   PixelSpacing_x   x   y  width  height  Target class  \n",
       "0        0.139000 NaN NaN    NaN     NaN     NaN   NaN  \n",
       "1        0.168000 NaN NaN    NaN     NaN     NaN   NaN  \n",
       "2        0.171000 NaN NaN    NaN     NaN     NaN   NaN  \n",
       "3        0.139000 NaN NaN    NaN     NaN     NaN   NaN  \n",
       "4        0.194311 NaN NaN    NaN     NaN     NaN   NaN  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_deduped.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "57771f449da5376e278d2f1d5fb2a87c9429d35a"
   },
   "source": [
    "Now that we have a data frame that links PatientID to DICOM data, let's merge this with train and the submission file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "b01cdbc166079c41d8c9f46569b90d1a5eb267bb"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'../input/jonneoofs/jonne_oofs.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-09bd3c5de97b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mjonneoofs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../input/jonneoofs/jonne_oofs.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mjonneoofs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjonneoofs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'patientID'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mandyharless_sub\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../input/andyharless/submission (7).csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lutz.kuenneke\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    707\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    708\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 709\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    710\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    711\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lutz.kuenneke\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    447\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 449\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    450\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lutz.kuenneke\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    816\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 818\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    819\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    820\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lutz.kuenneke\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1047\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1048\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1049\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1050\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1051\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lutz.kuenneke\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1693\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'allow_leading_cols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1694\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1695\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1696\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1697\u001b[0m         \u001b[1;31m# XXX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: File b'../input/jonneoofs/jonne_oofs.csv' does not exist"
     ]
    }
   ],
   "source": [
    "#TODO: Input my on prediction\n",
    "\n",
    "jonneoofs = pd.read_csv(\"../input/jonneoofs/jonne_oofs.csv\")\n",
    "jonneoofs = jonneoofs.sort_values('patientID').reset_index(drop=True)\n",
    "andyharless_sub = pd.read_csv(\"../input/andyharless/submission (7).csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8e6b8032ab8e7c83e3f265b5bca218a19948b5e7"
   },
   "outputs": [],
   "source": [
    "labels.head() #The real train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "56debf2037e46dbf564aea9279e6edd142c0a095"
   },
   "outputs": [],
   "source": [
    "jonneoofs.head() #The oofs from Jonne's kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "551cbf6e07851f929353171afe1654427f0ab563"
   },
   "outputs": [],
   "source": [
    "andyharless_sub.head() # The submission from Andy Harless, which is a fork from Jonne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7f456d4892c19c0e56b9723111aaa9dbc17e6709"
   },
   "outputs": [],
   "source": [
    "jonneoofs['i_am_train'] = 1\n",
    "andyharless_sub['i_am_train'] = 0\n",
    "tr_te = jonneoofs.append(andyharless_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "836ea815df6a29031255c767ecca8debc32d8431"
   },
   "outputs": [],
   "source": [
    "del tr_te['confidence'] #Not used in grading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6afd50f78f7cd76b7b265ddd6e8891d49ba734b5"
   },
   "outputs": [],
   "source": [
    "tr_te.columns = ['PatientID','x_guess','y_guess','width_guess','height_guess','i_am_train']\n",
    "tr_te.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b5b982e665cbc305175fe0a1a6f868a81e30dd86"
   },
   "outputs": [],
   "source": [
    "df_deduped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8309095dde427e2d876520651b49765da98c7057"
   },
   "outputs": [],
   "source": [
    "merged_df = tr_te.merge(df_deduped, how='left', on='PatientID')\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "846ea6f5479ec3322fdd5a0ed73bc5917c06e98e"
   },
   "outputs": [],
   "source": [
    "filledmerged_df = merged_df.fillna(-1) #Fill in missings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2548f4be8e49d2bc137a252e8cf3c08ee7feb107"
   },
   "source": [
    "# Predict for x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3ca6f7aef369604a91d1d8c1f2550c912e435a71"
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "train_df = filledmerged_df[filledmerged_df['i_am_train']==1]\n",
    "test_df = filledmerged_df[filledmerged_df['i_am_train']==0]\n",
    "             \n",
    "#Cross validate with K Fold, 5 splits\n",
    "folds = KFold(n_splits= 5, shuffle=True, random_state=2222)\n",
    "\n",
    "# Create arrays and dataframes to store results\n",
    "oof_preds = np.zeros(train_df.shape[0])\n",
    "sub_preds = np.zeros(test_df.shape[0])\n",
    "             \n",
    "feats = [f for f in train_df.columns if f not in ['PatientID', 'i_am_train', 'x','y','width','height','Target','class']]\n",
    "\n",
    "for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train_df[feats])):\n",
    "    dtrain = lgb.Dataset(data=train_df[feats].iloc[train_idx], \n",
    "                         label=train_df['x'].iloc[train_idx], \n",
    "                         free_raw_data=False, silent=True)\n",
    "    dvalid = lgb.Dataset(data=train_df[feats].iloc[valid_idx], \n",
    "                         label=train_df['x'].iloc[valid_idx], \n",
    "                         free_raw_data=False, silent=True)\n",
    "\n",
    "    params = {\n",
    "        'objective': 'regression',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'nthread': 4,\n",
    "        'learning_rate': 0.10, \n",
    "        'max_depth': 2,\n",
    "        #'reg_alpha': 0,\n",
    "        #'reg_lambda': 0,\n",
    "        #'min_split_gain': 0.0222415,\n",
    "        'seed': 15000,\n",
    "        'verbose': 50,\n",
    "        'metric': 'l2',\n",
    "    }\n",
    "\n",
    "    clf = lgb.train(\n",
    "        params=params,\n",
    "        train_set=dtrain,\n",
    "        num_boost_round=1000,\n",
    "        valid_sets=[dtrain, dvalid],\n",
    "        early_stopping_rounds=50,\n",
    "        verbose_eval=True\n",
    "    )\n",
    "\n",
    "    oof_preds[valid_idx] = clf.predict(dvalid.data)\n",
    "    sub_preds += clf.predict(test_df[feats]) / folds.n_splits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0ab85d7941f91e0d0039425d4055a611a86049a6"
   },
   "outputs": [],
   "source": [
    "xpreds_oof = oof_preds.copy()\n",
    "xpreds_sub = sub_preds.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9412fd7fe5d60e0895bee79e47758a4e93e7c74c"
   },
   "source": [
    "# Predict for y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1742c3128b050cf21345205dbda5b3a6cc2590ca"
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "train_df = filledmerged_df[filledmerged_df['i_am_train']==1]\n",
    "test_df = filledmerged_df[filledmerged_df['i_am_train']==0]\n",
    "             \n",
    "#Cross validate with K Fold, 5 splits\n",
    "folds = KFold(n_splits= 5, shuffle=True, random_state=2222)\n",
    "\n",
    "# Create arrays and dataframes to store results\n",
    "oof_preds = np.zeros(train_df.shape[0])\n",
    "sub_preds = np.zeros(test_df.shape[0])\n",
    "             \n",
    "feats = [f for f in train_df.columns if f not in ['PatientID', 'i_am_train', 'x','y','width','height','Target','class']]\n",
    "\n",
    "for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train_df[feats])):\n",
    "    dtrain = lgb.Dataset(data=train_df[feats].iloc[train_idx], \n",
    "                         label=train_df['y'].iloc[train_idx], \n",
    "                         free_raw_data=False, silent=True)\n",
    "    dvalid = lgb.Dataset(data=train_df[feats].iloc[valid_idx], \n",
    "                         label=train_df['y'].iloc[valid_idx], \n",
    "                         free_raw_data=False, silent=True)\n",
    "\n",
    "    params = {\n",
    "        'objective': 'regression',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'nthread': 4,\n",
    "        'learning_rate': 0.10, \n",
    "        'max_depth': 2,\n",
    "        #'reg_alpha': 0,\n",
    "        #'reg_lambda': 0,\n",
    "        #'min_split_gain': 0.0222415,\n",
    "        'seed': 15000,\n",
    "        'verbose': 50,\n",
    "        'metric': 'l2',\n",
    "    }\n",
    "\n",
    "    clf = lgb.train(\n",
    "        params=params,\n",
    "        train_set=dtrain,\n",
    "        num_boost_round=1000,\n",
    "        valid_sets=[dtrain, dvalid],\n",
    "        early_stopping_rounds=50,\n",
    "        verbose_eval=True\n",
    "    )\n",
    "\n",
    "    oof_preds[valid_idx] = clf.predict(dvalid.data)\n",
    "    sub_preds += clf.predict(test_df[feats]) / folds.n_splits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0f9bcd81b195a0950c838590c1684c0a341abe63"
   },
   "outputs": [],
   "source": [
    "ypreds_oof = oof_preds.copy()\n",
    "ypreds_sub = sub_preds.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "20dec65f7184ecb700e90ca20c0e208bab0af6f4"
   },
   "source": [
    "# Predict for width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "76798f48a253465cd00df1d9520208efdaf3f482"
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "train_df = filledmerged_df[filledmerged_df['i_am_train']==1]\n",
    "test_df = filledmerged_df[filledmerged_df['i_am_train']==0]\n",
    "             \n",
    "#Cross validate with K Fold, 5 splits\n",
    "folds = KFold(n_splits= 5, shuffle=True, random_state=2222)\n",
    "\n",
    "# Create arrays and dataframes to store results\n",
    "oof_preds = np.zeros(train_df.shape[0])\n",
    "sub_preds = np.zeros(test_df.shape[0])\n",
    "             \n",
    "feats = [f for f in train_df.columns if f not in ['PatientID', 'i_am_train', 'x','y','width','height','Target','class']]\n",
    "\n",
    "for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train_df[feats])):\n",
    "    dtrain = lgb.Dataset(data=train_df[feats].iloc[train_idx], \n",
    "                         label=train_df['width'].iloc[train_idx], \n",
    "                         free_raw_data=False, silent=True)\n",
    "    dvalid = lgb.Dataset(data=train_df[feats].iloc[valid_idx], \n",
    "                         label=train_df['width'].iloc[valid_idx], \n",
    "                         free_raw_data=False, silent=True)\n",
    "\n",
    "    params = {\n",
    "        'objective': 'regression',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'nthread': 4,\n",
    "        'learning_rate': 0.10, \n",
    "        'max_depth': 2,\n",
    "        #'reg_alpha': 0,\n",
    "        #'reg_lambda': 0,\n",
    "        #'min_split_gain': 0.0222415,\n",
    "        'seed': 15000,\n",
    "        'verbose': 50,\n",
    "        'metric': 'l2',\n",
    "    }\n",
    "\n",
    "    clf = lgb.train(\n",
    "        params=params,\n",
    "        train_set=dtrain,\n",
    "        num_boost_round=1000,\n",
    "        valid_sets=[dtrain, dvalid],\n",
    "        early_stopping_rounds=50,\n",
    "        verbose_eval=True\n",
    "    )\n",
    "\n",
    "    oof_preds[valid_idx] = clf.predict(dvalid.data)\n",
    "    sub_preds += clf.predict(test_df[feats]) / folds.n_splits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f8e804c15a83c3aee288c609aefa863ec867cd67"
   },
   "outputs": [],
   "source": [
    "widthpreds_oof = oof_preds.copy()\n",
    "widthpreds_sub = sub_preds.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "62f1d25f02f8be016f7d9be5875fb9344fc36d65"
   },
   "source": [
    "# Predict for height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "206c949dea0f197d6643f120089a9006d3e9952a"
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "train_df = filledmerged_df[filledmerged_df['i_am_train']==1]\n",
    "test_df = filledmerged_df[filledmerged_df['i_am_train']==0]\n",
    "             \n",
    "#Cross validate with K Fold, 5 splits\n",
    "folds = KFold(n_splits= 5, shuffle=True, random_state=2222)\n",
    "\n",
    "# Create arrays and dataframes to store results\n",
    "oof_preds = np.zeros(train_df.shape[0])\n",
    "sub_preds = np.zeros(test_df.shape[0])\n",
    "             \n",
    "feats = [f for f in train_df.columns if f not in ['PatientID', 'i_am_train', 'x','y','width','height','Target','class']]\n",
    "\n",
    "for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train_df[feats])):\n",
    "    dtrain = lgb.Dataset(data=train_df[feats].iloc[train_idx], \n",
    "                         label=train_df['height'].iloc[train_idx], \n",
    "                         free_raw_data=False, silent=True)\n",
    "    dvalid = lgb.Dataset(data=train_df[feats].iloc[valid_idx], \n",
    "                         label=train_df['height'].iloc[valid_idx], \n",
    "                         free_raw_data=False, silent=True)\n",
    "\n",
    "    params = {\n",
    "        'objective': 'regression',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'nthread': 4,\n",
    "        'learning_rate': 0.10, \n",
    "        'max_depth': 2,\n",
    "        #'reg_alpha': 0,\n",
    "        #'reg_lambda': 0,\n",
    "        #'min_split_gain': 0.0222415,\n",
    "        'seed': 15000,\n",
    "        'verbose': 50,\n",
    "        'metric': 'l2',\n",
    "    }\n",
    "\n",
    "    clf = lgb.train(\n",
    "        params=params,\n",
    "        train_set=dtrain,\n",
    "        num_boost_round=1000,\n",
    "        valid_sets=[dtrain, dvalid],\n",
    "        early_stopping_rounds=50,\n",
    "        verbose_eval=True\n",
    "    )\n",
    "\n",
    "    oof_preds[valid_idx] = clf.predict(dvalid.data)\n",
    "    sub_preds += clf.predict(test_df[feats]) / folds.n_splits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3cc639e4b9c6f928a4472d7e49ca30f9a3645ae4"
   },
   "outputs": [],
   "source": [
    "heightpreds_oof = oof_preds.copy()\n",
    "heightpreds_sub = sub_preds.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b75e25bb054f34ae1b98b635fe67796bfd4f75cc"
   },
   "source": [
    "# Remove any boxes below a threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cbcf2adb6305fcae77130b30178c08e993c21b13"
   },
   "outputs": [],
   "source": [
    "# What is the number of rows where we have a box?\n",
    "train_df.loc[train_df['x'] > -1]['x'].shape[0] / train_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4291061afaf94d42dee0fe93bef8f911d638de01"
   },
   "source": [
    "0.22 rows have a box, so now let's cull our predictions until only there is 0.22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7e9689a1018015520adde4903d377dcf3d38a9db"
   },
   "outputs": [],
   "source": [
    "train_df['xpredsoof'] = xpreds_oof\n",
    "train_df['ypredsoof'] = ypreds_oof\n",
    "train_df['widthpredsoof'] = widthpreds_oof\n",
    "train_df['heightpredsoof'] = heightpreds_oof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bac620c20f01a62748a1dd3089fff2a2996998fb"
   },
   "outputs": [],
   "source": [
    "train_df.loc[train_df['widthpredsoof'] <= 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d26f359cff69875629aaaf59263eb9deef2681d9"
   },
   "outputs": [],
   "source": [
    "#train_df.loc[(train_df['xpredsoof'] > 130) & (train_df['ypredsoof'] > 134)].shape[0] / train_df.shape[0]\n",
    "train_df.loc[(train_df['widthpredsoof'] > 100)].shape[0] / train_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3fef99695ddf9ca4d7e379a10dcd41c580988d30"
   },
   "outputs": [],
   "source": [
    "andyharless_sub['xpred'] = xpreds_sub\n",
    "andyharless_sub['ypred'] = ypreds_sub\n",
    "andyharless_sub['widthpred'] = widthpreds_sub\n",
    "andyharless_sub['heightpred'] = heightpreds_sub\n",
    "\n",
    "andyharless_sub['xpred'] = andyharless_sub['xpred'].round()\n",
    "andyharless_sub['ypred'] = andyharless_sub['ypred'].round()\n",
    "andyharless_sub['widthpred'] = andyharless_sub['widthpred'].round()\n",
    "andyharless_sub['heightpred'] = andyharless_sub['heightpred'].round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3080b5acee23e706b1444f616ddb89b592782050"
   },
   "outputs": [],
   "source": [
    "#andyharless_sub.loc[andyharless_sub['widthpred'] <= 100, 'xpred'] = ''\n",
    "#andyharless_sub.loc[andyharless_sub['widthpred'] <= 100, 'ypred'] = ''\n",
    "#andyharless_sub.loc[andyharless_sub['widthpred'] <= 100, 'heightpred'] = ''\n",
    "#andyharless_sub.loc[andyharless_sub['widthpred'] <= 100, 'widthpred'] = ''\n",
    "andyharless_sub['confidence'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9a350cb09d43078f2e92da6c9c17700ec113f3ca"
   },
   "outputs": [],
   "source": [
    "andyharless_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a510c61098607a5f4bffbe3abc20aaf82becebe8"
   },
   "outputs": [],
   "source": [
    "#del andyharless_sub['x']\n",
    "#del andyharless_sub['y']\n",
    "#del andyharless_sub['width']\n",
    "#del andyharless_sub['height']\n",
    "#del andyharless_sub['i_am_train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4515e16976a0694c20b0e516142489d8d73606fd"
   },
   "outputs": [],
   "source": [
    "andyharless_sub['PredictionString'] = andyharless_sub['confidence'].map(str)+' '+andyharless_sub['xpred'].map(str)+' '+andyharless_sub['ypred'].map(str)+' '+andyharless_sub['widthpred'].map(str)+' '+andyharless_sub['heightpred'].map(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a7fd9e03aee46dae2e6d4e3621df275cb77b270c"
   },
   "outputs": [],
   "source": [
    "andyharless_sub.loc[andyharless_sub['PredictionString']=='1    ', 'PredictionString'] = '' #Correct empties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8945035e527f1320f3d78c36a35b7fd16211cdf6"
   },
   "outputs": [],
   "source": [
    "andyharless_sub.loc[andyharless_sub['x'].isnull(), 'PredictionString'] = '' #Remove boxes if we predicted there were none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "83dff05122ce8e44e270dbebb1e5351fc01fb78f"
   },
   "outputs": [],
   "source": [
    "andyharless_sub[['patientID','PredictionString']].to_csv('dicom_corrections.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cd31ba9603c36ed609057baba48a98598f32c8c6"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
